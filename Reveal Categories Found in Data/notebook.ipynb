{"cells":[{"source":"![wordcloud](wordcloud.png)\n\nAs a Data Scientist working for a mobile app company, you usually find yourself applying product analytics to better understand user behavior, uncover patterns, and reveal insights to identify the great and not-so-great features. Recently, the number of negative reviews has increased on Google Play, and as a consequence, the app's rating has been decreasing. The team has requested you to analyze the situation and make sense of the negative reviews.\n\nIt's up to you to apply K-means clustering from scikit-learn and NLP techniques through NLTK to sort text data from negative reviews in the Google Play Store into categories!\n\n## The Data\n\nA dataset has been shared with a sample of reviews and their respective scores (from 1 to 5) in the Google Play Store. A summary and preview are provided below.\n\n# reviews.csv\n\n| Column     | Description              |\n|------------|--------------------------|\n| `'content'` | Content (text) of each review. |\n| `'score'` | Score assigned to the review by the user as an integer (from 1 to 5). |","metadata":{},"id":"c79a760b-d438-41bb-b1a1-2578773c0fe0","cell_type":"markdown"},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Download necessary files from NLTK:\n# punkt -> Tokenization\n# stopwords -> Stop words removal\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")\n\n# Load the reviews dataset and preview it\nreviews = pd.read_csv(\"reviews.csv\")\nreviews.head()\n\n# Step 1: Preprocess the negative reviews\n\n# Filter negative reviews (having a score of 1 or 2)\nnegative_reviews_tmp = reviews[(reviews[\"score\"] == 1) | (reviews[\"score\"] == 2)][\"content\"]\n\ndef preprocess_text(text):\n    \"\"\"Performs all the required steps in the text preprocessing\"\"\"\n\n    # Tokenizing the text\n    tokens = word_tokenize(text)\n\n    # Removing stop words and non-alpha characters\n    filtered_tokens = [\n        token\n        for token in tokens\n        if token.isalpha() and token.lower() not in stopwords.words(\"english\")\n    ]\n\n    return \" \".join(filtered_tokens)\n\n\n# Apply the preprocessing function to the negative reviews\nnegative_reviews_cleaned = negative_reviews_tmp.apply(preprocess_text)\n\n# Store the preprocessed negative reviews in a pandas DataFrame\npreprocessed_reviews = pd.DataFrame({\"review\": negative_reviews_cleaned})\npreprocessed_reviews.head()\n\n# Step 2: Vectorize the cleaned negative reviews using TF-IDF\n\n# Vectorize the cleaned reviews using TF-IDF\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"review\"])\n\n# Step 3: Apply K-means clustering to tfidf_matrix\n\n# Apply K-means clustering (store the model as clust_kmeans)\nclust_kmeans = KMeans(n_clusters=5, random_state=500)\npred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n\n# Store the predicted labels in a list variable called categories\ncategories = pred_labels.tolist()\npreprocessed_reviews[\"category\"] = categories\n\n# Step 4: For each unique cluster label, find the most frequent term\n\n# Get the feature names (terms) from the vectorizer\nterms = vectorizer.get_feature_names_out()\n\n# List to save the top term for each cluster\ntopic_terms_list = []\n\nfor cluster in range(clust_kmeans.n_clusters):\n    # Get indices of reviews in the current cluster\n    cluster_indices = [i for i, label in enumerate(categories) if label == cluster]\n\n    # Sum the tf-idf scores for each term in the cluster\n    cluster_tfidf_sum = tfidf_matrix[cluster_indices].sum(axis=0)\n    cluster_term_freq = np.asarray(cluster_tfidf_sum).ravel()\n\n    # Get the top term and its frequencies\n    top_term_index = cluster_term_freq.argsort()[::-1][0]\n\n    # Append rows to the topic_terms DataFrame with three fields:\n    # - category: label / cluster assigned from K-means\n    # - term: the identified top term\n    # - frequency: term's weight for the category\n    topic_terms_list.append(\n        {\n            \"category\": cluster,\n            \"term\": terms[top_term_index],\n            \"frequency\": cluster_term_freq[top_term_index],\n        }\n    )\n\n# Pandas DataFrame to store results from this step\ntopic_terms = pd.DataFrame(topic_terms_list)\n\n# Output the final result\nprint(topic_terms)\n","metadata":{"executionCancelledAt":null,"executionTime":18201,"lastExecutedAt":1722666476183,"lastExecutedByKernel":"92000ba8-a1b6-4720-bdcc-2f8d228c931c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Download necessary files from NLTK:\n# punkt -> Tokenization\n# stopwords -> Stop words removal\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")\n\n# Load the reviews dataset and preview it\nreviews = pd.read_csv(\"reviews.csv\")\nreviews.head()\n\n# Step 1: Preprocess the negative reviews\n\n# Filter negative reviews (having a score of 1 or 2)\nnegative_reviews_tmp = reviews[(reviews[\"score\"] == 1) | (reviews[\"score\"] == 2)][\"content\"]\n\ndef preprocess_text(text):\n    \"\"\"Performs all the required steps in the text preprocessing\"\"\"\n\n    # Tokenizing the text\n    tokens = word_tokenize(text)\n\n    # Removing stop words and non-alpha characters\n    filtered_tokens = [\n        token\n        for token in tokens\n        if token.isalpha() and token.lower() not in stopwords.words(\"english\")\n    ]\n\n    return \" \".join(filtered_tokens)\n\n\n# Apply the preprocessing function to the negative reviews\nnegative_reviews_cleaned = negative_reviews_tmp.apply(preprocess_text)\n\n# Store the preprocessed negative reviews in a pandas DataFrame\npreprocessed_reviews = pd.DataFrame({\"review\": negative_reviews_cleaned})\npreprocessed_reviews.head()\n\n# Step 2: Vectorize the cleaned negative reviews using TF-IDF\n\n# Vectorize the cleaned reviews using TF-IDF\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"review\"])\n\n# Step 3: Apply K-means clustering to tfidf_matrix\n\n# Apply K-means clustering (store the model as clust_kmeans)\nclust_kmeans = KMeans(n_clusters=5, random_state=500)\npred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n\n# Store the predicted labels in a list variable called categories\ncategories = pred_labels.tolist()\npreprocessed_reviews[\"category\"] = categories\n\n# Step 4: For each unique cluster label, find the most frequent term\n\n# Get the feature names (terms) from the vectorizer\nterms = vectorizer.get_feature_names_out()\n\n# List to save the top term for each cluster\ntopic_terms_list = []\n\nfor cluster in range(clust_kmeans.n_clusters):\n    # Get indices of reviews in the current cluster\n    cluster_indices = [i for i, label in enumerate(categories) if label == cluster]\n\n    # Sum the tf-idf scores for each term in the cluster\n    cluster_tfidf_sum = tfidf_matrix[cluster_indices].sum(axis=0)\n    cluster_term_freq = np.asarray(cluster_tfidf_sum).ravel()\n\n    # Get the top term and its frequencies\n    top_term_index = cluster_term_freq.argsort()[::-1][0]\n\n    # Append rows to the topic_terms DataFrame with three fields:\n    # - category: label / cluster assigned from K-means\n    # - term: the identified top term\n    # - frequency: term's weight for the category\n    topic_terms_list.append(\n        {\n            \"category\": cluster,\n            \"term\": terms[top_term_index],\n            \"frequency\": cluster_term_freq[top_term_index],\n        }\n    )\n\n# Pandas DataFrame to store results from this step\ntopic_terms = pd.DataFrame(topic_terms_list)\n\n# Output the final result\nprint(topic_terms)\n","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"id":"48172b7a-d771-435b-a6fe-c99134ac5eba","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"},{"output_type":"stream","name":"stdout","text":"   category      term   frequency\n0         0       app  186.525216\n1         1   version   63.738669\n2         2      good   52.935519\n3         3   premium   55.750426\n4         4  calendar   70.971649\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}